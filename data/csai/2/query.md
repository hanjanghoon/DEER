Write a rigorous, self-contained academic paper that establishes an upper bound on the circuit complexity of the family of formal languages recognized by average-hard-attention saturated Transformers with float activations. Precisely define the transformer model (inputs, outputs/acceptance, parameters L(n),H(n),d(n),b(n),watt(n)L(n),H(n),d(n),b(n),w_{\text{att}}(n), positional encoding, saturation/averaging rules) and the target circuit model (gate basis, fan-in, size/depth, uniformity). The paper should carefully define the model and its necessary parameters, formalize the mechanisms involved, construct appropriate circuit simulations, and analyze upper bounds across different growth regimes. If needed, add conditions for the existence of such an upper bound.
